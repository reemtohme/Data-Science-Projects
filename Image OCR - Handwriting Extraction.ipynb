{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_by_name(folder_path, target_filename):\n",
    "    \"\"\"\n",
    "    Loads a specific image from a folder using OpenCV.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing images.\n",
    "        target_filename (str): Name of the image file to load.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (filename, image_array) if found, else None.\n",
    "    \"\"\"\n",
    "    img_path = os.path.join(folder_path, target_filename)\n",
    "\n",
    "    # Check if the file exists and is an image\n",
    "    if os.path.exists(img_path) and target_filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "        image = cv2.imread(img_path)  \n",
    "        if image is not None:\n",
    "            return (target_filename, image)\n",
    "        else:\n",
    "            print(f\"Warning: Could not load {target_filename}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Error: '{target_filename}' not found in '{folder_path}'.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_image_horizontally(image, percentage=20):\n",
    "    \"\"\"\n",
    "    Slices the image horizontally by a given percentage.\n",
    "    Returns both the top and bottom slices.\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    slice_height = int((percentage / 100) * height)\n",
    "\n",
    "    top_slice = image[:slice_height, :]\n",
    "    bottom_slice = image[-slice_height:, :]\n",
    "\n",
    "    return top_slice, bottom_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_slices(top_slice, bottom_slice):\n",
    "    \"\"\"\n",
    "    Converts BGR images to RGB and displays them side by side using Matplotlib.\n",
    "\n",
    "    Args:\n",
    "        top_slice (numpy.ndarray): The top slice of the image.\n",
    "        bottom_slice (numpy.ndarray): The bottom slice of the image.\n",
    "    \"\"\"\n",
    "    if top_slice is None or bottom_slice is None:\n",
    "        raise ValueError(\"Error: One or both image slices are None.\")\n",
    "\n",
    "    # Convert BGR to RGB for correct Matplotlib display\n",
    "    top_slice_rgb = cv2.cvtColor(top_slice, cv2.COLOR_BGR2RGB)\n",
    "    bottom_slice_rgb = cv2.cvtColor(bottom_slice, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.figure(figsize=(24, 18))\n",
    "\n",
    "    # Display top slice\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(top_slice_rgb)\n",
    "    plt.title(\"Top Slice\")\n",
    "    plt.axis(\"off\") \n",
    "\n",
    "    # Display bottom slice\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(bottom_slice_rgb)\n",
    "    plt.title(\"Bottom Slice\")\n",
    "    plt.axis(\"off\") \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejoin_slices(top_slice, bottom_slice):\n",
    "    \"\"\"\n",
    "    Rejoins two slices (top and bottom) back into a single image.\n",
    "    \n",
    "    Args:\n",
    "    - top_slice (numpy.ndarray): The top portion of the sliced image.\n",
    "    - bottom_slice (numpy.ndarray): The bottom portion of the sliced image.\n",
    "    \n",
    "    Returns:\n",
    "    - numpy.ndarray: The rejoined image.\n",
    "    \"\"\"\n",
    "    # Ensure both slices have the same width\n",
    "    if top_slice.shape[1] != bottom_slice.shape[1]:\n",
    "        raise ValueError(\"Top and bottom slices must have the same width\")\n",
    "    \n",
    "    # Stack the slices vertically (along the height axis)\n",
    "    rejoined_image = np.vstack((top_slice, bottom_slice))\n",
    "    \n",
    "    return rejoined_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_image_width(image_array, slice_width=500):\n",
    "    \"\"\"\n",
    "    Slices a large image (as a NumPy array) into smaller chunks by width only.\n",
    "    \n",
    "    Args:\n",
    "    - image_array (numpy.ndarray): Image as a NumPy array.\n",
    "    - output_dir (str): Directory to save the sliced chunks.\n",
    "    - slice_width (int): Width of each slice.\n",
    "    \n",
    "    Returns:\n",
    "    - List of file paths for the sliced images.\n",
    "    \"\"\"\n",
    "    double_sliced_images = []\n",
    "    # Get the width and height of the image from the NumPy array\n",
    "    img_height, img_width, _ = image_array.shape\n",
    "    \n",
    "    # Slice the image by width\n",
    "    for i, left in enumerate(range(0, img_width, slice_width)):\n",
    "        # Define the slice box (only width changes)\n",
    "        right = min(left + slice_width, img_width)\n",
    "        \n",
    "        # Slice the image (using NumPy array slicing)\n",
    "        slice_img = image_array[:, left:right]\n",
    "        double_sliced_images.append(slice_img)\n",
    "    \n",
    "    return double_sliced_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_slices(sliced_images):\n",
    "    \"\"\"\n",
    "    Visualizes the slices created by slice_image_width function.\n",
    "    \n",
    "    Args:\n",
    "    - sliced_images (list of numpy.ndarray): List of sliced images.\n",
    "    - slice_width (int): The width of each slice (used for figure size adjustment).\n",
    "    \"\"\"\n",
    "    num_slices = len(sliced_images)\n",
    "    \n",
    "    plt.figure(figsize=(10, num_slices * 2))  # Adjust the height dynamically based on the number of slices\n",
    "    \n",
    "    for i, slice_img in enumerate(sliced_images):\n",
    "        plt.subplot(num_slices, 1, i + 1)  # Create a subplot for each slice\n",
    "        plt.imshow(slice_img)\n",
    "        plt.title(f\"Slice {i + 1}\")  \n",
    "        plt.axis('off')  \n",
    "   \n",
    "    plt.tight_layout()  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_slices(image_slices, angle=90):\n",
    "    \"\"\"\n",
    "    Rotates a list of image slices by a specified angle.\n",
    "\n",
    "    Args:\n",
    "        image_slices (list of numpy.ndarray): List of image slices.\n",
    "        angle (float): Angle by which to rotate each image (default is 90Â° clockwise).\n",
    "\n",
    "    Returns:\n",
    "        list of numpy.ndarray: List of rotated image slices.\n",
    "    \"\"\"\n",
    "    rotated_slices = []\n",
    "    \n",
    "    for img in image_slices:\n",
    "        if img is None:\n",
    "            rotated_slices.append(None)\n",
    "            continue  \n",
    "\n",
    "        # Get image dimensions\n",
    "        (h, w) = img.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "\n",
    "        # Compute rotation matrix\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "\n",
    "        # Compute the new bounding dimensions\n",
    "        cos = np.abs(M[0, 0])\n",
    "        sin = np.abs(M[0, 1])\n",
    "        new_w = int((h * sin) + (w * cos))\n",
    "        new_h = int((h * cos) + (w * sin))\n",
    "\n",
    "        # Adjust the rotation matrix to keep the full image\n",
    "        M[0, 2] += (new_w / 2) - center[0]\n",
    "        M[1, 2] += (new_h / 2) - center[1]\n",
    "\n",
    "        # Rotate image\n",
    "        rotated = cv2.warpAffine(img, M, (new_w, new_h), borderMode=cv2.BORDER_REPLICATE)\n",
    "        rotated_slices.append(rotated)\n",
    "\n",
    "    return rotated_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_display_text(image_slices):\n",
    "    \"\"\"\n",
    "    Detects text in multiple image slices using EasyOCR and displays them in a grid.\n",
    "\n",
    "    Args:\n",
    "        image_slices (list): List of image slices (NumPy arrays).\n",
    "    \"\"\"\n",
    "    if not image_slices:\n",
    "        raise ValueError(\"Error: No image slices provided.\")\n",
    "\n",
    "    reader = easyocr.Reader(['en'], gpu=True)\n",
    "\n",
    "    def detect_text(image):\n",
    "        \"\"\"Detects text in a single image slice.\"\"\"\n",
    "        results = reader.readtext(image, detail=0)  # Extract only text (no bounding box)\n",
    "        return results\n",
    "\n",
    "    num_slices = len(image_slices)\n",
    "    \n",
    "    # Define grid layout (adjust the number of columns as needed)\n",
    "    cols = min(num_slices, 4)  # Max 4 images per row\n",
    "    rows = (num_slices + cols - 1) // cols  # Calculate required rows\n",
    "\n",
    "    # Create a single figure with subplots\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 5))  \n",
    "    axes = axes.ravel()  # Flatten in case of multiple rows\n",
    "\n",
    "    for i, (slice_img, ax) in enumerate(zip(image_slices, axes)):\n",
    "        if slice_img is None:\n",
    "            ax.axis(\"off\")\n",
    "            continue \n",
    "\n",
    "        # Convert BGR to RGB for Matplotlib display\n",
    "        slice_rgb = cv2.cvtColor(slice_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect text in the slice\n",
    "        detected_text = detect_text(slice_img)\n",
    "        text_display = ' | '.join(detected_text) if detected_text else 'No text detected'\n",
    "\n",
    "        # Display image slice\n",
    "        ax.imshow(slice_rgb)\n",
    "        ax.set_title(f\"Slice {i+1}\\n{text_display}\", fontsize=10)\n",
    "        ax.axis(\"off\")  # Hide axes\n",
    "\n",
    "    # Hide any unused subplots if num_slices is less than total grid size\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label_half(image_slices):\n",
    "    \"\"\"\n",
    "    Detects which half (left or right) of the image contains text and returns only that half.\n",
    "\n",
    "    Args:\n",
    "        image_slices (list of numpy.ndarray): List of image slices.\n",
    "\n",
    "    Returns:\n",
    "        list of numpy.ndarray: List of image halves (sliced vertically after rotation) that contain the label.\n",
    "    \"\"\"\n",
    "    extracted_halves = []\n",
    "\n",
    "    for img in image_slices:\n",
    "        if img is None:\n",
    "            extracted_halves.append(None)\n",
    "            continue  \n",
    "        \n",
    "        # Convert to grayscale for text detection\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        h, w = gray.shape[:2]\n",
    "        \n",
    "        # Split the image into left and right halves\n",
    "        left_half = gray[:, :w//2]\n",
    "        right_half = gray[:, w//2:]\n",
    "\n",
    "        # Compute edge density using Canny edge detection (text usually has strong edges)\n",
    "        left_edges = cv2.Canny(left_half, 50, 150)\n",
    "        right_edges = cv2.Canny(right_half, 50, 150)\n",
    "\n",
    "        # Count non-zero pixels (edges) in each half\n",
    "        left_score = np.sum(left_edges > 0)\n",
    "        right_score = np.sum(right_edges > 0)\n",
    "\n",
    "        # Determine which side has more edges (likely the label)\n",
    "        if right_score > left_score:\n",
    "            extracted_halves.append(img[:, w//2:])  # Keep right half\n",
    "        else:\n",
    "            extracted_halves.append(img[:, :w//2])  # Keep left half\n",
    "\n",
    "    return extracted_halves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/mnt/shared/eric/Full_Set_Processed/PARA2_BGSUB_wavelet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARA2_BGSUB_Wavelet_processed_img = load_image_by_name('/mnt/shared/eric/Full_Set_Processed/PARA2_BGSUB_wavelet/PROCESSED' , '1968_3_19396513.jpeg_processed.tiff')\n",
    "PARA2_BGSUB_Wavelet_binary_img = load_image_by_name('/mnt/shared/eric/Full_Set_Processed/PARA2_BGSUB_wavelet/BINARIES' , '1968_3_19396513.jpeg_binary.tiff' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_top_processed, first_bottom_processed = slice_image_horizontally(PARA2_BGSUB_Wavelet_processed_img[1])\n",
    "first_rejoined_processed = rejoin_slices(first_top_processed, first_bottom_processed)\n",
    "first_processed_slices = slice_image_width(first_rejoined_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_and_display_text(rotate_slices(first_processed_slices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_top_binary, first_bottom_binary = slice_image_horizontally(PARA2_BGSUB_Wavelet_binary_img[1])\n",
    "first_rejoined_binary = rejoin_slices(first_top_binary, first_bottom_binary)\n",
    "first_binary_slices = slice_image_width(first_rejoined_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_and_display_text(rotate_slices(first_binary_slices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/mnt/shared/eric/Full_Set_Processed/Full_set_PARA2_NoBGSub_wavelet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARA2_NoBGSub_wavelet_processed_img = load_image_by_name('/mnt/shared/eric/Full_Set_Processed/Full_set_PARA2_NoBGSub_wavelet/PROCESSED', '1968_3_19396513.jpeg_processed.tiff')\n",
    "PARA2_NoBGSub_wavelet_binary_img = load_image_by_name('/mnt/shared/eric/Full_Set_Processed/Full_set_PARA2_NoBGSub_wavelet/BINARIES','1968_3_19396513.jpeg_binary.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_top_processed, second_bottom_processed= slice_image_horizontally(PARA2_NoBGSub_wavelet_processed_img[1])\n",
    "second_rejoined_processed = rejoin_slices(second_top_processed, second_bottom_processed)\n",
    "second_processed_slices = slice_image_width(second_rejoined_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_and_display_text(rotate_slices(second_processed_slices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_top_binary, second_bottom_binary = slice_image_horizontally(PARA2_NoBGSub_wavelet_binary_img[1])\n",
    "second_rejoined_binary = rejoin_slices(second_top_binary, second_bottom_binary)\n",
    "second_binary_slices = slice_image_width(second_rejoined_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_and_display_text(rotate_slices(second_binary_slices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/mnt/shared/eric/Full_Set_Processed/PARA2_BGSUB-nLMean/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARA2_BGSUB_nLMean_processed_img = load_image_by_name('/mnt/shared/eric/Full_Set_Processed/PARA2_BGSUB-nLMean/PROCESSED', '1968_3_19396513.jpeg_processed.tiff')\n",
    "PARA2_BGSUB_nLMean_binary_img = load_image_by_name('/mnt/shared/eric/Full_Set_Processed/PARA2_BGSUB-nLMean/BINARIES','1968_3_19396513.jpeg_binary.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_top_processed, third_bottom_processed = slice_image_horizontally(PARA2_BGSUB_nLMean_processed_img[1])\n",
    "third_rejoined_processed = rejoin_slices(third_top_processed, third_bottom_processed)\n",
    "third_processed_slices = slice_image_width(third_rejoined_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_and_display_text(rotate_slices(third_processed_slices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_top_binary, third_bottom_binary = slice_image_horizontally(PARA2_BGSUB_nLMean_binary_img[1])\n",
    "third_rejoined_binary = rejoin_slices(third_top_binary, third_bottom_binary)\n",
    "third_binary_slices = slice_image_width(third_rejoined_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_and_display_text(rotate_slices(third_binary_slices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/mnt/shared/eric/Full_Set_Processed/Full_Set_PARA2_noBGSub_nLMeans/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARA2_noBGSub_nLMeans_processed_img = load_image_by_name('/mnt/shared/eric/Full_Set_Processed/Full_Set_PARA2_noBGSub_nLMeans/PROCESSED', '1968_3_19396513.jpeg_processed.tiff')\n",
    "PARA2_noBGSub_nLMeans_binary_img = load_image_by_name('/mnt/shared/eric/Full_Set_Processed/Full_Set_PARA2_noBGSub_nLMeans/BINARIES','1968_3_19396513.jpeg_binary.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_top_processed, fourth_bottom_processed = slice_image_horizontally(PARA2_noBGSub_nLMeans_processed_img[1])\n",
    "fourth_rejoined_processed = rejoin_slices(fourth_top_processed, fourth_bottom_processed)\n",
    "fourth_processed_slices = slice_image_width(fourth_rejoined_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_and_display_text(rotate_slices(fourth_processed_slices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_top_binary, fourth_bottom_binary = slice_image_horizontally(PARA2_noBGSub_nLMeans_binary_img[1])\n",
    "fourth_rejoined_binary = rejoin_slices(fourth_top_binary, fourth_bottom_binary)\n",
    "fourth_binary_slices = slice_image_width(fourth_rejoined_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_and_display_text(rotate_slices(fourth_binary_slices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/mnt/shared/eric/Full_Set_Processed/Full_Set_No_BG_Subtract_Wavelet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "No_BG_Subtract_Wavelet_processed_img = load_image_by_name('/mnt/shared/eric/Full_Set_Processed/Full_Set_No_BG_Subtract_Wavelet/PROCESSED', '1968_3_19396513.jpeg_processed.tiff')\n",
    "No_BG_Subtract_Wavelet_binary_img = load_image_by_name('/mnt/shared/eric/Full_Set_Processed/Full_Set_No_BG_Subtract_Wavelet/BINARIES','1968_3_19396513.jpeg_binary.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifth_top_processed, fifth_bottom_processed = slice_image_horizontally(No_BG_Subtract_Wavelet_processed_img[1])\n",
    "fifth_rejoined_processed = rejoin_slices(fifth_top_processed, fifth_bottom_processed)\n",
    "fifth_processed_slices = slice_image_width(fifth_rejoined_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_and_display_text(rotate_slices(fifth_processed_slices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifth_top_binary, fifth_bottom_binary = slice_image_horizontally(No_BG_Subtract_Wavelet_binary_img[1])\n",
    "fifth_rejoined_binary = rejoin_slices(fifth_top_binary, fifth_bottom_binary)\n",
    "fifth_binary_slices = slice_image_width(fifth_rejoined_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_and_display_text(rotate_slices(fifth_binary_slices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/mnt/shared/eric/Full_Set_Processed/Full_Set_No_BG_Subtract_nLMeans/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "No_BG_Subtract_nLMeans_processed_img = load_image_by_name('/mnt/shared/eric/Full_Set_Processed/Full_Set_No_BG_Subtract_nLMeans/PROCESSED', '1968_3_19396513.jpeg_processed.tiff')\n",
    "No_BG_Subtract_nLMeans_binary_img = load_image_by_name('/mnt/shared/eric/Full_Set_Processed/Full_Set_No_BG_Subtract_nLMeans/BINARIES','1968_3_19396513.jpeg_binary.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sixth_top_processed, sixth_bottom_processed = slice_image_horizontally(No_BG_Subtract_nLMeans_processed_img[1])\n",
    "sixth_rejoined_processed = rejoin_slices(sixth_top_processed, sixth_bottom_processed)\n",
    "sixth_processed_slices = slice_image_width(sixth_rejoined_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_and_display_text(rotate_slices(sixth_processed_slices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sixth_top_binary, sixth_bottom_binary = slice_image_horizontally(No_BG_Subtract_nLMeans_binary_img[1])\n",
    "sixth_rejoined_binary = rejoin_slices(sixth_top_binary, fourth_bottom_binary)\n",
    "sixth_binary_slices = slice_image_width(sixth_rejoined_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_and_display_text(rotate_slices(sixth_binary_slices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ORIGINALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_img = load_image_by_name('/mnt/input/Images', '1968_3_19396513.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_top_binary, original_bottom_binary = slice_image_horizontally(original_img[1])\n",
    "original_rejoined_binary = rejoin_slices(original_top_binary, original_bottom_binary)\n",
    "original_binary_slices = slice_image_width(original_rejoined_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_and_display_text(rotate_slices(original_binary_slices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed that in the sliced images, easyOCR more accurate detects the wrtitten text at the edges of the image since it is written in a bigger font than the targeted labels on the image itself. To attempt at making the image fed to easyOCR more zoomed in on the label, or in other words, the labels to appear in a bigger font for more accurate detection, we tried to further slice the rotated images vertically in half and extract the halves the contain the labels without relying on easyOCR. Instead, since text usually has strong edges, we attempted at detecting thr labels using Canny edge detection, and on that basis, extract the image with the labels to apply easyOCR on. However, this approach was not successful in detecting the labeled halves in the majority of the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sixth_rotated_processed_slices = rotate_slices(sixth_processed_slices)\n",
    "halves = extract_label_half(sixth_rotated_processed_slices)\n",
    "visualize_slices(halves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label_half_ocr(image_slices):\n",
    "    \"\"\"\n",
    "    Uses OCR to determine which half (left or right) of an image contains text \n",
    "    and returns only that half.\n",
    "\n",
    "    Args:\n",
    "        image_slices (list of numpy.ndarray): List of image slices.\n",
    "\n",
    "    Returns:\n",
    "        list of numpy.ndarray: List of image halves that contain the label.\n",
    "    \"\"\"\n",
    "    reader = easyocr.Reader(['en'], gpu=True)  \n",
    "    extracted_halves = []\n",
    "\n",
    "    for img in image_slices:\n",
    "        if img is None:\n",
    "            extracted_halves.append(None)\n",
    "            continue \n",
    "        \n",
    "        # Convert to grayscale (optional, OCR can handle color)\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        # Split the image into left and right halves\n",
    "        left_half = img[:, :w//2]\n",
    "        right_half = img[:, w//2:]\n",
    "\n",
    "        # Run OCR on both halves\n",
    "        left_text = reader.readtext(left_half, detail=0)  # Extract text only\n",
    "        right_text = reader.readtext(right_half, detail=0)\n",
    "\n",
    "        # Determine which side has more detected text\n",
    "        if len(right_text) > len(left_text):\n",
    "            extracted_halves.append(right_half)  \n",
    "        else:\n",
    "            extracted_halves.append(left_half)\n",
    "            \n",
    "    return extracted_halves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sixth_rotated_processed_slices = rotate_slices(sixth_processed_slices)\n",
    "halves = extract_label_half_ocr(sixth_rotated_processed_slices)\n",
    "visualize_slices(halves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_and_display_text(halves)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
